{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Routing Tutorial\n",
    "\n",
    "In this notebook, we'll cover the basics routing hillslope discharge time series through a channel network. To learn more about how to simulate hillslope discharge, see the [hillslope discharge tutorial notebook](hillslope_discharge.ipynb). To learn more about how to create a channel network topoolgy and geometry from a digital elevation map, check out the [REW extraction tutorial](network_extraction_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first need to import some classes to populate the channels of our REWs. The modules that are imported here must include all vadose zone, groundwater zone, and channel models that are specified below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "parent_dir = dirname(dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(parent_dir,'StreamflowTempModel','3_channel_routing'))\n",
    "\n",
    "from channel import SimpleChannel, NoChannel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to set up some data structures to hold REW parameters and forcing data. We'll assume that these have already been computed and have been stored in the `model_data` subfolder of the parent folder. We'll then need to set some model parameters related to timescales and simuluation domains. These are both very similar to the set up in the [hillslope discharge tutorial notebook](hillslope_discharge.ipynb), and so we won't go into too much detail here. It's worth noting that we specify different timescales for hillslope discharge and channel routing. This provides us the flexibility to dial down the channel routing time step in order to ensure numerical convergence of the kinematic wave solver, while still allowing a coarser timestep for the more simple hillslope discharge solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These dictionaries contain the all the data we'll need to instantiate \n",
    "rew_config = pickle.load( open( os.path.join(parent_dir,'model_data','rew_config.p'), \"rb\" ) )\n",
    "climate_group_forcing = pickle.load( open( os.path.join(parent_dir,'model_data','climate_group_forcing.p'), \"rb\" ) )\n",
    "model_config = pickle.load( open( os.path.join(parent_dir, 'model_data', 'model_config.p'), 'rb'))\n",
    "channel_params = pickle.load( open( os.path.join(parent_dir,'model_data','channel_params.p'), \"rb\" ))\n",
    "hill_groups = pickle.load( open( os.path.join(parent_dir,'model_data','solved_hillslope_discharge.p'), \"rb\" ) )\n",
    "\n",
    "#start/stop dates for running model  \n",
    "#spinup date is the date after start_date for which we assume model is finished spinning up         \n",
    "start_date = model_config['start_date']\n",
    "stop_date = model_config['stop_date']\n",
    "spinup_date = model_config['spinup_date']\n",
    "Tmax = model_config['Tmax']\n",
    "dt = model_config['dt_channel']\n",
    "resample_freq_channel = model_config['resample_freq_channel']\n",
    "resample_freq_hillslope = model_config['resample_freq_hillslope']\n",
    "timestamps_hillslope = pd.date_range(start_date, stop_date, freq=resample_freq_hillslope)\n",
    "timestamps_channel = pd.date_range(start_date, stop_date, freq=resample_freq_channel)\n",
    "t = np.linspace(0,Tmax,np.ceil(Tmax/dt)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `channel_params` file must contain a dictionary whose keys are REW IDs, and whose values are themselves dictionaries. These key-value pairs of these inner dictionaries the attribute names and values required to fully populate the user-specified `Channel` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_network = {}\n",
    "for rew_id in rew_config.keys(): \n",
    "    args = rew_config[rew_id].copy()\n",
    "    args.update(channel_params[rew_id])\n",
    "    channel_network[rew_id] = args['model'](rew_id=rew_id, **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute each channel's discharge time series, starting from the headwaters and moving downstream. There are many ways we might compute an acceptable ordering of channels, but GRASS GIS has already computed one for us; the Shreve index of a stream is defined as 1 if the stream is at the headwaters, and as the sum of its parents' Shreve indices otherwise. We can therefore simply compute channel flow starting with all channels with Shreve index 1 and work our way forward. \n",
    "\n",
    "The workhorse function in channel routing is the `update` method required by any inheritor of the abstract `Channel` class. As in solving any nonlinear ODE, there is always the risk of introducing numerical instability in this update method if the time step is not sufficiently small. In this example, we have included a simple proof of concept testing procedure that raises a flag if the channel would be completely evacuated in a single timestep given the current velocity.\n",
    "\n",
    "We save discharge data as a dictionary whose keys are REW IDs and whose values are time series; this file is placed in `network_volumetric_discharges` in the `model_data` folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_volumetric_discharges = {}\n",
    "\n",
    "rew_ids = rew_config.keys()\n",
    "shreves = [rew_config[rew_id]['shreve'] for rew_id in rew_ids]\n",
    "\n",
    "channelQueue = [rew_id for (shreve,rew_id) in sorted(zip(shreves,rew_ids))]\n",
    "\n",
    "print \"Solve REWs in this order:\"\n",
    "print(channelQueue)\n",
    "\n",
    "for rew_id in channelQueue:\n",
    "    print 'Working on REW ' + str(rew_id)\n",
    "    width = []\n",
    "    length = []\n",
    "    shreve  = rew_config[rew_id]['shreve']\n",
    "    group_id = rew_config[rew_id]['group']\n",
    "    climate_group_id = group_id[1]\n",
    "    ppt = np.array(climate_group_forcing[climate_group_id][start_date:stop_date].ppt.resample(resample_freq_channel).ffill())\n",
    "    hillslope_discharge = pd.DataFrame({'discharge':hill_groups[group_id]['discharge']}, index=hill_groups[group_id].index)\n",
    "    hillslope_overlandFlow = pd.DataFrame({'overlandFlow':hill_groups[group_id]['overlandFlow']}, index=hill_groups[group_id].index)\n",
    "    hillslope_discharge['discharge'] = hillslope_discharge['discharge'] + hillslope_overlandFlow['overlandFlow']\n",
    "    hillslope_volumetric_discharge = np.array(hillslope_discharge[start_date:stop_date].discharge.resample(resample_freq_channel).ffill())*rew_config[rew_id]['area_sqcm']\n",
    "    volumetric_discharge = np.zeros(np.size(t))\n",
    "    volumes = np.zeros(np.size(t))\n",
    "    approx = 0\n",
    "    \n",
    "    if shreve == 1:\n",
    "        up = np.zeros(np.shape(t))\n",
    "    else:\n",
    "        upstream_1 = rew_config[rew_id]['prev_str01']\n",
    "        upstream_2 = rew_config[rew_id]['prev_str02']\n",
    "        \n",
    "        vol_1 = network_volumetric_discharges[upstream_1].volumetric_discharge#.resample(resample_freq_channel).ffill()\n",
    "        vol_2 = network_volumetric_discharges[upstream_2].volumetric_discharge#.resample(resample_freq_channel).ffill()\n",
    "        \n",
    "        up = np.array(vol_1 + vol_2)\n",
    "    \n",
    "    for i in range(len(t)):\n",
    "        volumes[i] = channel_network[rew_id].volume\n",
    "        result = channel_network[rew_id].update(dt, upstream_volumetric_discharge=up[i], hillslope_volumetric_discharge=hillslope_volumetric_discharge[i] , ppt=ppt[i])\n",
    "        approx = (approx or result)\n",
    "        volumetric_discharge[i]=channel_network[rew_id].volumetric_discharge\n",
    "        width.append(channel_network[rew_id].width)\n",
    "        length.append(channel_network[rew_id].length)\n",
    "\n",
    "    if approx==1: \n",
    "        print '\\nWarning: Numerical instability encountered. Consider decreasing timestep size. \\nDischarge for REW ' + str(rew_id) + ' had to be approximated for some timesteps. \\n'\n",
    "\n",
    "    network_volumetric_discharges[rew_id]=pd.DataFrame({'volumetric_discharge':volumetric_discharge, 'volumes':volumes, 'width':width, 'length':length}, index=timestamps_channel)\n",
    "\n",
    "\n",
    "stores = ['volumes']\n",
    "for rew_id in channelQueue:\n",
    "    df = pd.DataFrame()\n",
    "    for col in network_volumetric_discharges[rew_id].columns:\n",
    "        if col in stores:\n",
    "            df[col] = network_volumetric_discharges[rew_id][col].resample('D').first()\n",
    "        else:\n",
    "            df[col] = network_volumetric_discharges[rew_id][col].resample('D').apply(sum)*dt\n",
    "            \n",
    "    network_volumetric_discharges[rew_id]=df\n",
    "    \n",
    "pickle.dump( network_volumetric_discharges, open( os.path.join(parent_dir,'model_data','solved_channel_routing.p'), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Find REW with largest total contributing area\n",
    "calibration_data_filename = 'sf_leggett_runoff.p'\n",
    "rew_ids = rew_config.keys()\n",
    "outlet_id = rew_ids[0]\n",
    "area_max = rew_config[outlet_id]['upstream_area']\n",
    "for rew_id in rew_ids:\n",
    "    if rew_config[rew_id]['upstream_area']>area_max:\n",
    "        outlet_id = rew_id\n",
    "        area_max = rew_config[rew_id]['upstream_area']\n",
    "        \n",
    "\n",
    "discharge = np.array(network_volumetric_discharges[outlet_id].volumetric_discharge/rew_config[outlet_id]['upstream_area'])\n",
    "data_df = pickle.load( open( os.path.join(parent_dir, 'calibration_data', calibration_data_filename), 'rb'))\n",
    "data_runoff_df = data_df['runoff'][start_date:stop_date]\n",
    "data_runoff = np.array(data_df['runoff'][start_date:stop_date])\n",
    "outflows_df = pd.DataFrame({'data':data_runoff, 'modeled':discharge}, index = data_runoff_df.index)\n",
    "outflows_df.loc[spinup_date:stop_date].plot(figsize=(10,8))\n",
    "plt.yscale('log')\n",
    "plt.xlim(['10-2013','8-2014'])\n",
    "# plt.ylim([10**-3, 10**1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def objective_function(modeled, observed):\n",
    "    inds = ((modeled != 0) & (observed != 0))\n",
    "    if np.sum(modeled)<0.01:\n",
    "        return -9999.0\n",
    "    elif np.isnan(np.sum(modeled)):\n",
    "        return -9999.0\n",
    "    else:\n",
    "        return 1-np.sum((np.log(observed.loc[inds])-np.log(modeled.loc[inds]))**2)/np.sum((np.log(observed.loc[inds])-np.mean(np.log(observed.loc[inds])))**2)\n",
    "\n",
    "objective_function(outflows_df.modeled.loc[spinup_date:stop_date], outflows_df.data.loc[spinup_date:stop_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vz = 0\n",
    "gz = 0\n",
    "stream = 0\n",
    "init = 0\n",
    "\n",
    "cumPpt = 0\n",
    "cumET = 0\n",
    "\n",
    "for rew in channelQueue:\n",
    "    group_id = rew_config[rew]['group']\n",
    "    climate_group_id = group_id[1]\n",
    "\n",
    "    area = rew_config[rew]['area_sqcm']\n",
    "\n",
    "    vz += hill_groups[group_id].storageVZ*area\n",
    "    gz += hill_groups[group_id].storageGZ*area\n",
    "    stream += network_volumetric_discharges[rew].volumes\n",
    "\n",
    "    # must account for precip that falls on both channel AND hillslope\n",
    "    ppt = climate_group_forcing[climate_group_id][start_date:stop_date].ppt*area \n",
    "    ppt_double_counted = ppt*(network_volumetric_discharges[rew].length*network_volumetric_discharges[rew].width)/area\n",
    "    ppt = ppt + ppt_double_counted\n",
    "    ET = hill_groups[group_id].ET*area\n",
    "    cumPpt += ppt.cumsum()\n",
    "    cumET += ET.cumsum()\n",
    "    if ~np.isfinite(network_volumetric_discharges[rew].width[0]):\n",
    "        print('Steady state channel model; no computed width. Ignore mass balance.')\n",
    "\n",
    "\n",
    "outDis = network_volumetric_discharges[outlet_id].volumetric_discharge\n",
    "cumOutDis = outDis.cumsum() \n",
    "\n",
    "\n",
    "\n",
    "S0 = stream[0] + gz[0] + vz[0]\n",
    "totalIn = np.array(cumPpt)\n",
    "S = np.array(gz + vz + stream)\n",
    "totalOut = np.array(cumET + cumOutDis)\n",
    "balance = (totalIn[:-1] - totalOut[:-1] + S0)/S[1:]\n",
    "plt.plot(balance)\n",
    "plt.ylim([0,1.1])\n",
    "print(np.max(balance))\n",
    "print(np.min(balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check balance of an individual channel \n",
    "for rew in rew_config.keys():\n",
    "    stream = network_volumetric_discharges[rew].volumes\n",
    "    length = channel_network[rew].length\n",
    "    width = channel_network[rew].width\n",
    "    area = length*width\n",
    "    group_id = rew_config[rew]['group']\n",
    "    climate_group_id = group_id[1]\n",
    "    ppt = climate_group_forcing[climate_group_id][start_date:stop_date].ppt*area \n",
    "    hillslope_discharge = pd.DataFrame({'discharge':hill_groups[group_id]['discharge']}, index=hill_groups[group_id].index)\n",
    "    hillslope_overlandFlow = pd.DataFrame({'overlandFlow':hill_groups[group_id]['overlandFlow']}, index=hill_groups[group_id].index)\n",
    "    hillslope_discharge['discharge'] = hillslope_discharge['discharge'] + hillslope_overlandFlow['overlandFlow']\n",
    "    hillslope_volumetric_discharge = hillslope_discharge[start_date:stop_date].discharge*rew_config[rew]['area_sqcm']\n",
    "\n",
    "\n",
    "    outDis = network_volumetric_discharges[rew].volumetric_discharge\n",
    "    cumOutDis = outDis.cumsum() \n",
    "\n",
    "    upstream_1 = rew_config[rew]['prev_str01']\n",
    "    upstream_2 = rew_config[rew]['prev_str02']\n",
    "    try:\n",
    "        vol_1 = network_volumetric_discharges[upstream_1].volumetric_discharge#.resample(resample_freq_channel).ffill()\n",
    "        vol_2 = network_volumetric_discharges[upstream_2].volumetric_discharge#.resample(resample_freq_channel).ffill()\n",
    "        inDis = vol_1 + vol_2 + hillslope_volumetric_discharge\n",
    "    except:\n",
    "        inDis = hillslope_volumetric_discharge\n",
    "\n",
    "\n",
    "    cumInDis = inDis.cumsum()\n",
    "\n",
    "    cumPpt = ppt.cumsum()\n",
    "\n",
    "\n",
    "    S0 = stream[0]\n",
    "    totalIn = np.array(cumPpt + cumInDis)\n",
    "    S =  np.array(stream)\n",
    "    totalOut = np.array(cumOutDis)\n",
    "    balance = (totalIn[:-1] - totalOut[:-1] + S0)/S[1:]\n",
    "    #balance = (totalIn[:-1] - totalOut[:-1] + S0)-S[1:]\n",
    "\n",
    "    # plt.plot(balance)\n",
    "#     print rew\n",
    "    # plt.ylim([0,1.1])\n",
    "#     print(np.max(balance))\n",
    "#     print(np.min(balance))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2k_model]",
   "language": "python",
   "name": "conda-env-py2k_model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
