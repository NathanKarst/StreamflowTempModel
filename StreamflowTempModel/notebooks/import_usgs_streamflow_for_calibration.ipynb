{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example script to convert USGS streamflow data into a calibration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from matplotlib import pylab\n",
    "import sys\n",
    "from os.path import dirname\n",
    "parent_dir = dirname(dirname(os.getcwd()))\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import geopandas as gp\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFlow(site):\n",
    "    '''\n",
    "        Input: USGS gage number\n",
    "        \n",
    "        Output: pandas data frame of volumetric streamflow (over period of record at the gage) indexed by datetime\n",
    "    '''\n",
    "    site = str(site)\n",
    "    url = 'https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no=' + site + '&referred_module=sw&period=&begin_date=1950-01-01&end_date=2017-09-01'\n",
    "    response = urllib2.urlopen(url)\n",
    "    content = response.read()\n",
    "    f = open('flow_data/'+ site+'.txt','w')\n",
    "    f.write(content)\n",
    "    f.close()\n",
    "    count = 0\n",
    "    for line in open('flow_data/'+ site+'.txt','r').readlines():\n",
    "        if line[0] == '#': \n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    df = pd.read_csv('flow_data/'+ site+'.txt', header=count, delimiter='\\t')\n",
    "    q_col = next(col for col in df.columns if col.endswith('00060_00003'))\n",
    "    df.rename(columns={q_col: 'q', 'datetime':'date'}, inplace=True)    \n",
    "    df = df.iloc[1:,:]\n",
    "    df = df.dropna()\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.q = pd.to_numeric(df.q)\n",
    "    df.index = pd.to_datetime(df.date)\n",
    "    return df\n",
    "\n",
    "def _finditem(obj, key):\n",
    "    if key in obj: return obj[key]\n",
    "    for k, v in obj.items():\n",
    "        if isinstance(v,dict):\n",
    "            return _finditem(v, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_data = gp.read_file('./USGS_gages/USGS_Streamgages-NHD_Locations.shp')\n",
    "sitelist = ['11475560']\n",
    "\n",
    "for gage in sitelist:\n",
    "    df = getFlow(gage)\n",
    "    rng = df.index\n",
    "    df = pd.DataFrame.from_dict({'runoff':df.q.values})\n",
    "    df.index = rng\n",
    "    df = df*2.44657555e9 # convert to cm^3/day\n",
    "    area = float(site_data['DA_SQ_MILE'].loc[site_data.SITE_NO==gage])*1/0.000000000039 # in cm^2\n",
    "    df = df/area\n",
    "    pickle.dump( df, open('../../calibration_data/'+gage+'_runoff.p', 'wb') )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2k_model]",
   "language": "python",
   "name": "conda-env-py2k_model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
